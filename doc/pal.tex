\documentclass{report}
\usepackage{fancyhdr}
\usepackage{setspace}
\usepackage{lipsum}
\usepackage{graphicx}
\pagestyle{fancy}
\lhead{CMPUT 415}
\chead{pal Compiler}
\rhead{Fall 2012}
\lfoot{Group 5}
\cfoot{}
\rfoot{\thepage}
\setlength{\parindent}{0pt}
\doublespacing

\title{CMPUT 415 - PAL Compiler\\Final Submission\\Program Documentation}
\author{Mike Bujold \\
Dan Chui \\ 
James Osgood }

\begin{document}
\maketitle
\textbf{The man page is available by typing} \emph{make man}

\section*{Introduction}
Our goals for this checkpoint are threefold:
\begin{enumerate}
\item Implement fully functional and correct lexical analysis.
\item Implement correct syntactical analysis, including adequate and meaningful error-detection and recovery.
\item Symbol table and semantic analysis.
\end{enumerate}

It is our ongoing intention to report on any errors in the program in a way that is meaningful to the user so that corrective action may be taken. The compiler must also recover from each error in such a manner that further reporting of errors is possible, up until the end of the program listing.\\
Currently, because of the limited functionality of the compiler, only the '-n' flag is operational when running \emph{pal}. The '-n' option supresses the program listing from being output.


\section*{Handling of Lexical Units}
Our lexer parses tokens in the following order: first, all single and multi-line comments are parsed, followed by reserved \emph{pal} keywords, then numbers and variable names. Relational operators and other lexical units are parsed last. Any remaining unparsed tokens are presumed invalid, and the grammar handles reporting the error accordingly.


\section*{Syntax Error Reporting \& Recovery}

The bulk of the error-handling code is in \emph{myerror.c}. The method we used for error handling is when an error is found, it is added to a linked list. As soon as we finish parsing a line, we output that list, clear it, and move onto the next line. \\
We also used a process of finding errors by creating what we call a "loop error" catcher. A "loop error" is an error in the code that bison knows about, but is unable to handle. It doesn't reduce or shift, it stays and does the same thing over and over again. We catch these by detecting if it occurs 300 times in a single line (in theory, there shouldn't be more than 300 errors on one line). \\
To recover from the loop error, we set yyparse to return a value of 1, which means there was an error and returns to the main function, where you do a while loop and detect if yyparse has returned a value greater than 0. After you output all errors caught, we go back to yyparse until it returns 0, that means it has parsed successfully. This is how we recover from a "loop error".\\
We took bison error tokens before semi-colons, 'begin' tokens, 'end' tokens and between brackets.\\
The errors are displayed by showing the program line, followed by all the errors in the line. It displays the line number, the character number in the line and the error that was detected (eg. syntax error). Underneath that line, it displays a 'caret' underneath the location of the error.\\
We created myerror.c to catch all the errors. When an error is found, it is added to a linked list. As soon as we finish parsing a line, we output that list, clear it, and move onto the next line.\\

The general syntactic error strategy we used was to place error symbols close to termnial symbols and near synchronizing symbols. 
By letting small statements and expressions, such as terms, assignments, and types, be reduced to errors, we can usually recover quickly from minor, localized errors. 
The placement of error symbols by important separators, such as ';', 'end', ']', and ')', in both recursive and nonrecursive contexts, ensures general recoverability from larger, more disruptive errors.
Additionally, large grammar constructs, such as declaration parts and the entire program, can protect against the parser being unable to recover for strange errors. 
To better handle error reporting in statements, we let conditionals reduce to errors, thus making 'else', 'then', and 'do' significant symbols. As a stop-gap, we implemented a loop counter that would kill the program if it became trapped in a seemingly infinite error reporting loop.
\\

The large amount of error symbols in the program has resulted in, what we think, a fairly comprehensive syntactic error reporter, although their are still some instances of open brackets and statements eating up a lot of the input; this number of error symbols have also cause twelve shift/reduce conflicts.


\section*{Symbol Table}
We used the glib-2.0 library to implement data structures within our compiler, primarily the symbol table.\\
Our symbol table is a stack; for each new scope, we push a new level onto the stack. Lookup then looks at the top of the stack for localLookup, and begins its lookup from the top of the stack to the bottom for globalLookup. Each level of the symbol table stack is a hash table, where the symbol is retrieved using its identifier.\\


\section*{Symbols}
Symbols are first divided into classes using an \texttt{object\_class} enumerated type which determines what object class the symbol belongs to (eg. var, const, function, etc.). Objects can then have a \texttt{type\_class} enumerated type which indicates what type of variable can be expected. \\
Symbols are stored in a \texttt{symbol\_rec} struct, which is composed of a symbol \texttt{name} field, an \texttt{object\_class} field, and a \texttt{oc\_descriptions} union, which contains further parameters based on which object class the record contains. The descriptions for each object class contain data that pertains to each class. For instance, the description for a \texttt{OC\_CONST} object would contain the value of the constant, the description for a \texttt{OC\_FUNCTION} object would contain a pointer to the list of parameters and the return type for that object.\\
Type Classes are a special object case that have a further structure with data pertinent to that variable. For instance, type class \texttt{TC\_SCALAR} has two extra fields in it's description, one for length and another to hold a pointer to the list of elements. Type symbols are special cases of symbols; they have a type\_attr description, which defines the type itself, and this type symbol is pointed to by other symbols, showing what type they are.\\


\section*{Semantic Analysis}
Most of the semantic analysis is done using the symbol structures, which are passed up the tree. Local and global lookups of the symbol table are used to determine the correct usage of symbols. Object classes and types are checked for consistency in declarations, assignments, operations, procedure and function invocations, conditionals, and array accesses.\\

To determine if a function's return value is set before the end of the function's definition, we check every assignment for a function symbol on the left hand side. This assignment is valid if the assignment occurs within the function's \texttt{compound\_stat} definition, which we check by setting flags before and after the \texttt{compound\_stat}. Any valid assignment to a function return value is carried up the tree, only invalidated by \texttt{if} statements and \texttt{while} loops. At an \texttt{if-then-else} statement, both parts must have values set to be a valid return value assignment.\\
We keep global variables for the current loop depth, incremented and decremented appropriately, to check for the correct placement of \texttt{exit} and \texttt{continue} statements.\\

I/O procedure invocations without parentheses (\texttt{write}, \texttt{read}, \texttt{writeln}, and \texttt{readln}) are checked using a lexical rule, a identifier reduction in the grammar (to allow for hiding the names), and a check if the symbol is the same as the corresponding builtin procedure (i.e. it has not been hidden).


\section*{Syntax Tree}
To generate the \emph{ASC} assembly code for a \emph{pal} program, we build a syntax tree of the program using the bison grammar structure. The nodes of the tree consist of a type indicator, the symbol resulting from the grammar rule (if present), and additional contructs that are required to do semantic analysis and symbol creation, but not code generation; for example, we require the parameters of a procedure declaration to create the associated symbol, but we do not need the parameters to generate code for the procedure because the parameters are stored in the procedure symbol itself.\\

After we have generated a syntax tree from this first pass, we reformat and simplify the tree to facilitate easier code generation. Lists in the tree are flattened, unnecessary nodes are collapsed (especially expression nodes), and a minor number of nodes are added for consistency reasons. Also, the additional constructs not involved in code generation removed from the nodes, leaving just the node type indicator and symbol (if present) remaining. The simplified tree has the following form:\\

\begin{figure}[ht]
\caption{Assignment}
\centering
\includegraphics[scale=0.25]{./doc/assignment.pdf}
\end{figure}

\begin{figure}[ht]
\caption{Program}
\centering
\includegraphics[scale=0.25]{./doc/program.pdf}
\end{figure}

\begin{figure}[ht]
\caption{Stat}
\centering
\includegraphics[scale=0.25]{./doc/stat.pdf}\\
\end{figure}

The only dedicated leaf nodes are \texttt{exit}, \texttt{continue}, and \texttt{symbol}, but \texttt{VAR\_DECL\_LIST}, \texttt{PROC\_DECL\_LIST},  and \texttt{STAT\_LIST} will also have no children if their respective sections are empty. Only the \texttt{symbol} node contains actual symbols.\\

An additional transformation take place before we generate code: arithmetic operators are modified to reflect the result of their computation, based on the type of their operands. We use a postorder traversal of the tree to recursively determine the type of the operands and set the operator's result type to real or integer accordingly. This final tree makes dealing with integer and real conversion, and determining the correct \emph{ASC} operator type, much easier.


\section*{Code Generation}
We use a postorder transveral (for most operations) to recursively generate code for program's syntax tree. Unique label identifiers are hashed into a large hash table which contain the actual label, based on a global counter of labels, since labels are only compared to 16 characters. The function/procedure calling protocol we use is:
\begin{itemize}
\item parameters are accessed with a negative offset from the indexing register, starting at -3.
\item the return value of a function is saved with an offset of -1 from the lowest parameter offset (i.e. below all the parameters).
\end{itemize}
\\
We handle 1-dimensional arrays, but arrays of larger dimension are handled non-deterministically (that is, they are not fully implemented). Run-time array bounds checking is also not implemented.


\section*{Testing}
To facilitate large scale testing and efficient reading of listing files, we created a python script to run the compiler on multiple tests and pipe the resulting output to a testing log.\\
When outputting program listings with the errors and line numbers appended, they are added to the program listing as comments, so the outputted program listing can be re-compiled an indefinite number of times.


\section*{Bugs/Features}
Since we do not strip out comments when listing the parsed file, the listing file may not be further parsable (that is, the listing may cause additional errors if run through the compiler). This is because of block comments, in a line where an error occurred, whose closed brackets interrupt the block comment of the error message added to the listing.

\section*{Math Functions}
Math functions must be implemented using the basic arithmetic operations available in \emph{ASC}. The degree of precision required for this project as set as accurate to 6 decimal places.
\subsection*{Natural Log}
The natural log (ln) function is calculated using a Mercator Series expansion:\\
$ formula here $ \\
The identity $ -ln(\frac{1}{x}) = ln(x)$ is used for values where $x > 1$.\\
The only problem with this method is that for very large values of x, some precision is lost. 

\subsection*{Exponential - $e^x$}
The value for $e^x$ is calculated using a Maclaurin Series expansion:\\
$ formula here $ \\

\end{document}